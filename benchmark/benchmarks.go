package benchmark

import (
	"bufio"
	"encoding/csv"
	"fmt"
	"log"
	"os"
	"strconv"
	"strings"
	"time"

	dataadapter "github.com/LexaTRex/timetravelDB/data-adapter"
	dataadapterneo4j "github.com/LexaTRex/timetravelDB/data-adapter-neo4j-only"
	datagenerator "github.com/LexaTRex/timetravelDB/data-generator"
	databaseapi "github.com/LexaTRex/timetravelDB/database-api"
	"github.com/LexaTRex/timetravelDB/query-processor/parser"
	qpe "github.com/LexaTRex/timetravelDB/query-processor/qpengine"
	"github.com/LexaTRex/timetravelDB/utils"
)

var logFile *os.File

var X = "2022-12-01T00:00:00Z"
var Y = "2022-12-02T00:00:00Z"

var responseTimes [7][100]time.Duration

var templates = []string{"graph_template_bm_1.yaml", "graph_template_bm_2.yaml", "graph_template_bm_3.yaml", "graph_template_bm_4.yaml", "graph_template_bm_5.yaml"}

// var templates = []string{"graph_template_bm_1.yaml", "graph_template_bm_2.yaml", "graph_template_bm_3.yaml"}
//var templates = []string{"graph_template_bm_3.yaml", "graph_template_bm_4.yaml", "graph_template_bm_5.yaml"}

func GenerateBenchmarkData() {

	utils.DEBUG = false

	for i, template := range templates {

		fmt.Println("Generate from template: ", template)

		// generate next dataset
		datagenerator.GenerateData(template)

		fmt.Println("Template " + strconv.Itoa(int(i)) + ": data generation complete.")
	}
}

func RunBenchmark() {

	logToFile("benchmark_log")
	defer logFile.Close()

	utils.DEBUG = false

	// test each dataset generated by the provided templates
	//for i, template := range templates { // loop begin
	for i := 0; i < len(templates); i++ {
		template := templates[i]

		// log.Println("generate from template: ", template)

		// // generate next dataset
		// datagenerator.GenerateData(template)

		// log.Println("Template " + strconv.Itoa(int(i)) + ": data generation complete.")

		/////////////////////////////
		// ttdb query benchmark: ////
		/////////////////////////////

		// clear databases
		databaseapi.ClearData()

		log.Println("Database cleared. Load dataset.")

		// load data to ttdb for ttql queries
		dataadapter.LoadData(template)

		log.Println("Finished Loading TTDB data for dataset ", strconv.Itoa(int(i)))

		log.Println("Start TTQL deep query benchmarks")

		// deep ttql queries
		RunBenchmarkTTDB(i, false)

		log.Println("TTQL deep Query benchmarks complete.")
		log.Println("Start TTQL shallow query benchmarks")

		// shallow ttql queries
		RunBenchmarkTTDB(i, true)

		log.Println("TTQL shallow Query benchmarks complete.")

		/////////////////////////////
		// cypher query benchmark: //
		/////////////////////////////

		// clear databases
		databaseapi.ClearData()

		log.Println("Database cleared. Load Neo4j dataset.")

		// load data to neo4j for cypher queries
		dataadapterneo4j.LoadData(template)

		log.Println("Finished Loading Neo4j data for dataset ", strconv.Itoa(int(i)))

		log.Println("Start Cypher query benchmarks")

		RunBenchmarkNeo4j(i)

		log.Println("Cypher Query benchmarks complete.")

		log.Println("all benchmarks completed for dataset ", i)
	}

}

// runs the benchmark queries on only Neo4j with the current contained data
func RunBenchmarkNeo4j(dataset int) {

	var results []map[string][]any

	for i, query := range neo4jQueries {
		log.Println("start query loop query number: ", i)

		log.Println("start warmup: ")

		// warmup run
		for j := 0; j < 5; j++ {
			databaseapi.ReadQueryNeo4j(query)
		}
		log.Println("warmup finished")
		log.Println("start measruement: ")

		// measurement run
		for j := 0; j < 20; j++ {

			start := time.Now()

			res, err := databaseapi.ReadQueryNeo4j(query)

			if err != nil {
				log.Printf("\n error querying neo4j: %v", err)
			}

			result, err := qpe.ResultToMap(res)

			end := time.Now()

			if err != nil {
				log.Printf("\nerror on result: %v", err)
			}

			results = append(results, result)
			utils.UNUSED(results)

			// Calculate the response time
			responseTime := end.Sub(start)
			if err != nil {
				responseTime = 0
			}
			responseTimes[i][j] = responseTime
			log.Printf("\nResponse Time: %v", responseTime)

			// writeValueToFile("neo4j-benchmark-result"+strconv.Itoa(dataset), i, responseTime)
		}
		log.Println("measurement finished.")
	}

	fmt.Println("*********************************************")
	fmt.Println("************* BENCHMARK RESULTS *************")
	fmt.Println("*********************************************")
	fmt.Println()

	writeResultToFile("neo4j-benchmark-result-"+strconv.Itoa(dataset), responseTimes)

	// for i := range neo4jQueries {
	// 	fmt.Println("Cypher Query : 	", i, " done")
	// 	// fmt.Print("Response Time : [")
	// 	// for j := 0; j < 100; j++ {
	// 	// 	fmt.Print(responseTimes[i][j], ", ")
	// 	// 	// fmt.Println("Result : ", results[i])
	// 	// }
	// 	// fmt.Print("]")
	// 	// fmt.Println()
	// }

	fmt.Println("*********************************************")
	fmt.Println("*********** BENCHMARK RESULTS END ***********")
	fmt.Println("*********************************************")

	log.Println("QUERY END")
	log.Println()
}

// runs the benchmark queries on TTDB (Neo4j & TimescaleDB) with the current contained data
func RunBenchmarkTTDB(dataset int, shallow bool) {

	var results []map[string][]any
	var queries []string

	if shallow {
		queries = ttDBQueriesShallow
	} else {
		queries = ttDBQueries
	}

	for i, query := range queries {
		log.Println("query number: ", i)

		query = cleanQuery(query)

		log.Println("start warmup: ")

		// warmup run
		for j := 0; j < 5; j++ {
			// Perform the database query
			queryInfo, _ := parser.ParseQuery(query)
			qpe.ProcessQuery(queryInfo)
		}

		log.Println("warmup finished")
		log.Println("start measurement: ")

		// measurement run
		for j := 0; j < 20; j++ {
			start := time.Now()

			// Perform the database query
			queryInfo, err := parser.ParseQuery(query)
			if err != nil {
				log.Fatalf("\n%v: error parsing query", err)
				return
			}
			res, err := qpe.ProcessQuery(queryInfo)
			if err != nil {
				log.Fatalf("processing query failed: %v", err)
				return
			}

			end := time.Now()

			results = append(results, res)
			utils.UNUSED(results)

			// Calculate the response time
			responseTime := end.Sub(start)
			responseTimes[i][j] = responseTime

			// if shallow {
			// 	writeValueToFile("ttdb-shallow-benchmark-result-dataset"+strconv.Itoa(dataset), i, responseTime)
			// } else {
			// 	writeValueToFile("ttdb-benchmark-result-dataset"+strconv.Itoa(dataset), i, responseTime)
			// }

		}
		log.Println("measurement finished.")

	}

	fmt.Println("*********************************************")
	fmt.Println("************* BENCHMARK RESULTS *************")
	fmt.Println("*********************************************")
	fmt.Println()

	log.Print("TTDB ")
	if shallow {
		log.Print("shalow ")
		writeResultToFile("ttdb-shallow-benchmark-result-dataset-"+strconv.Itoa(dataset), responseTimes)
	} else {
		writeResultToFile("ttdb-benchmark-result-dataset-"+strconv.Itoa(dataset), responseTimes)
	}

	log.Println("done ")

	// 	fmt.Println("Query : 	", i, " done")
	// for i := range ttDBQueries {
	// 	// fmt.Print("Response Time : [")
	// 	// for j := 0; j < 100; j++ {
	// 	// 	fmt.Print(responseTimes[i][j], ", ")
	// 	// 	// fmt.Println("Result : ", results[i])
	// 	// }
	// 	fmt.Print("]")
	// 	fmt.Println()
	// }

	fmt.Println("*********************************************")
	fmt.Println("*********** BENCHMARK RESULTS END ***********")
	fmt.Println("*********************************************")
}

//
//
//
//
// Query a single node
//
// `MATCH (n) WHERE ID(n) = 10 AND n.start = X AND n.start = Y RETURN n`
//
// TTDB
//   Query a single node shallow
//   "FROM X TO Y SHALLOW MATCH (n) WHERE ID(n) = 10 RETURN n"
//   Query a single node
//   "FROM X TO Y MATCH (n) WHERE ID(n) = 10 RETURN n"
//
// ON:
//   Query a time series property of a single node (by ID)
//     MATCH (n) WHERE ID(n) = 10 n.start = X AND n.start = Y RETURN n.ts_property*"
// TTDB
//   Query a time series property of a single node (by ID)
//     FROM X TO Y MATCH (n) WHERE ID(n) = 10 RETURN n.ts_property"
//
// ON:
//   Query a time series property of all nodes (that have this property)
//     MATCH (n) WHERE n.start = X AND n.start = Y RETURN n.ts_property*"
// TTDB
//   Query a time series property of all nodes (that have this property)
//     FROM X TO Y MATCH (n) RETURN n.ts_property"
//
// ON:
//   Query all time series properties of a single node
//   "MATCH (n) WHERE ID(n) = 10 AND n.start = X AND n.start = Y RETURN properties(n)"
// TTDB
//   Query all time series properties of a single node
//   "FROM X TO Y MATCH (n) WHERE ID(n) = 10 RETURN n.prop1, n.prop2, ..."
//
//
// ON:
//   Query all time series properties of all nodes
//   "MATCH (n) WHERE n.start = X AND n.start = Y RETURN properties(n)"
// TTDB
//   Query all time series properties of all nodes
//   "FROM X TO Y MATCH (n) RETURN n.prop1, n.prop2, ..."
//
//
//
// // Querying Time Series Data: the ANY OPERATOR
//
// ON:
//   Query a time series property of all nodes (that have this property)
//     MATCH (n) WHERE n.start = X AND n.start = Y AND (n.ts_property... > 20 OR n.ts_property.. > 20 OR ... ) RETURN n.ts_property*"
// TTDB
//   Query a time series property of all nodes (that have this property)
//     FROM X TO Y MATCH (n) AND ANY(n.ts_property > 20) RETURN n.ts_property"
//
//

func cleanQuery(query string) string {
	// Split the query into three parts: MATCH, WHERE, and RETURN
	parts := strings.Split(query, "WHERE")
	if len(parts) != 2 {
		// Query doesn't have a WHERE clause, return the original query
		return query
	}

	matchClause := parts[0]
	whereClause := parts[1]
	returnClause := ""
	returnIndex := strings.Index(whereClause, "RETURN")
	if returnIndex != -1 {
		returnClause = whereClause[returnIndex:]
		whereClause = whereClause[:returnIndex]
	}

	// Replace any() with a.prop
	whereClause = strings.ReplaceAll(whereClause, "any(", "")
	whereClause = strings.ReplaceAll(whereClause, "ANY(", "")
	whereClause = strings.ReplaceAll(whereClause, "Any(", "")
	whereClause = strings.ReplaceAll(whereClause, ")", "")

	// Reassemble the query
	query = matchClause + "WHERE " + whereClause + returnClause
	return query
}

func writeValueToFile(filename string, queryNr int, singleResult time.Duration) {
	lines := []string{}

	// Check if the file exists
	_, err := os.Stat(filename + ".csv")
	if os.IsExist(err) {
		// Read the existing content of the file
		file, err := os.Open(filename + ".csv")
		if err != nil {
			panic(err)
		}
		defer file.Close()

		scanner := bufio.NewScanner(file)
		for scanner.Scan() {
			lines = append(lines, scanner.Text())
		}
	}

	// Update the specified line with the new value
	if queryNr < len(lines) {
		line := lines[queryNr]
		line += "," + strconv.Itoa(int(singleResult))
		lines[queryNr] = line
	} else {
		// If the specified line does not exist, create new lines with empty content
		for len(lines) < queryNr {
			lines = append(lines, "")
		}
		lines = append(lines, strconv.Itoa(int(singleResult)))
	}

	// Write the updated content back to the file
	file, err := os.Create(filename + ".csv")
	if err != nil {
		panic(err)
	}
	defer file.Close()

	csvwriter := csv.NewWriter(file)
	defer csvwriter.Flush()

	for _, line := range lines {
		row := strings.Split(line, ",")
		err := csvwriter.Write(row)
		if err != nil {
			panic(err)
		}
	}
}

func writeResultToFile(filename string, result [7][100]time.Duration) {
	file, err := os.Create(filename + ".csv")

	// Create a new file for writing
	if err != nil {
		panic(err)
	}
	defer file.Close()

	// Create a new buffered writer
	csvwriter := csv.NewWriter(file)
	defer csvwriter.Flush()

	// Loop through the 2D array and write each element to the file

	// Loop through the 2D array and write each row to the CSV file
	for _, row := range result {
		// Create a new string slice to hold the string values of each element in the row
		var strRow []string
		for _, val := range row {
			// Convert the time.Duration value to a string
			strVal := strconv.Itoa(int(val))
			// Add the string value to the row slice
			strRow = append(strRow, strVal)
		}
		// Write the row of string values to the CSV file
		err := csvwriter.Write(strRow)
		if err != nil {
			panic(err)
		}
	}

}

func logToFile(filename string) {

	var err error

	// Create a file for logging
	logFile, err = os.OpenFile(filename+".txt", os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0666)
	if err != nil {
		log.Fatal(err)
	}

	// Set the output destination for the log package to the created file
	log.SetOutput(logFile)
}

// queries are  put to the end of the file for better readability

var neo4jQueries []string = []string{

	//////////
	// #1 ////
	//////////

	// query single node with id 0 if intersection with X to Y
	// this is not the whole query ! we still gotta filter all the properties for the time
	// could not find an cypher equivalent to the ttql query. I would need to know every property name beforehand
	// probably somehow possible with apoc query
	// which adds additional functionality
	// see: ~/Documents/school/master_thesis/research_fetch_single_node_filter_properties_only_neo4j
	// NOTE: time series inside elements not filtered by time interval
	"MATCH (n) WHERE n.nodeid = 0 AND n.end >= datetime('" + X + "') AND n.start <= datetime('" + Y + "') RETURN n",

	//////////
	// #2 ////
	//////////

	// query single time series property of single node from X to Y
	// with all time series entries that between  X and Y

	`MATCH (n)
	 	WHERE n.nodeid = 0 AND n.end >= datetime('` + X + `') AND n.start <= datetime('` + Y + `')` +
		`WITH n, [prop IN keys(n) WHERE prop STARTS WITH 'ts_Risc_'] AS riscProps
	  	  WITH n, size(riscProps) / 2 AS ts_Risc_numbers
	 		WITH n, range(0, ts_Risc_numbers - 1) AS indices
	  RETURN
	 		REDUCE(acc = [], i IN indices |
	 			acc + CASE
	 				WHEN n['ts_Risc_' + i + '_time'] >= datetime('2022-12-01T00:00:00Z') AND n['ts_Risc_' + i + '_time'] < datetime('2022-12-02T00:00:00Z') THEN [n['ts_Risc_' + i + '_time'],n['ts_Risc_' + i + '_value']]
	 				ELSE null
	 			END
	 		) AS props`,

	//////////
	// #4 ////
	//////////

	// query multiple time series properties of a single node
	`MATCH (n)
	 	WHERE n.nodeid = 0 AND n.end >= datetime('2022-12-01T00:00:00Z') AND n.start <= datetime('2022-12-02T00:00:00Z')
	 	WITH n,
	 	  [prop IN keys(n) WHERE prop STARTS WITH 'ts_IP_'] AS ts_IP_props,
	 	  [prop IN keys(n) WHERE prop STARTS WITH 'ts_Risc_'] AS ts_Risc_props,
	 	  [prop IN keys(n) WHERE prop STARTS WITH 'ts_Risc1_'] AS ts_Risc1_props,
	 	  [prop IN keys(n) WHERE prop STARTS WITH 'ts_Risc2_'] AS ts_Risc2_props
	 	WITH n,
	 	  size(ts_IP_props) / 2 AS ts_IP_numbers,
	 	  size(ts_Risc_props) / 2 AS ts_Risc_numbers,
	 	  size(ts_Risc1_props) / 2 AS ts_Risc1_numbers,
	 	  size(ts_Risc2_props) / 2 AS ts_Risc2_numbers,
	 	  ts_IP_props,
	 	  ts_Risc_props,
	 	  ts_Risc1_props,
	 	  ts_Risc2_props
	 	WITH n,
	 	  range(0, ts_IP_numbers - 1) AS ts_IP_indices,
	 	  range(0, ts_Risc_numbers - 1) AS ts_Risc_indices,
	 	  range(0, ts_Risc1_numbers - 1) AS ts_Risc1_indices,
	 	  range(0, ts_Risc2_numbers - 1) AS ts_Risc2_indices,
	 	  ts_IP_props,
	 	  ts_Risc_props,
	 	  ts_Risc1_props,
	 	  ts_Risc2_props
	 	RETURN
	 	  REDUCE(acc = [], i IN ts_IP_indices |
	 	    acc + CASE
	 	      WHEN n['ts_IP_' + i + '_time'] >= datetime('2022-12-01T00:00:00Z') AND n['ts_IP_' + i + '_time'] < datetime('2022-12-02T00:00:00Z') THEN [n['ts_IP_' + i + '_time'], n['ts_IP_' + i + '_value']]
	 	      ELSE null
	 	    END
	 	  ) AS ts_IP_props,
	 	  REDUCE(acc = [], i IN ts_Risc_indices |
	 	    acc + CASE
	 	      WHEN n['ts_Risc_' + i + '_time'] >= datetime('2022-12-01T00:00:00Z') AND n['ts_Risc_' + i + '_time'] < datetime('2022-12-02T00:00:00Z') THEN [n['ts_Risc_' + i + '_time'], n['ts_Risc_' + i + '_value']]
	 	      ELSE null
	 	    END
	 	  ) AS ts_Risc_props,
	 	  REDUCE(acc = [], i IN ts_Risc1_indices |
	 	    acc + CASE
	 	      WHEN n['ts_Risc1_' + i + '_time'] >= datetime('2022-12-01T00:00:00Z') AND n['ts_Risc1_' + i + '_time'] < datetime('2022-12-02T00:00:00Z') THEN [n['ts_Risc1_' + i + '_time'], n['ts_Risc1_' + i + '_value']]
	 	      ELSE null
	 	    END
	 	  ) AS ts_Risc1_props,
	 	  REDUCE(acc = [], i IN ts_Risc2_indices |
	 	    acc + CASE
	 	      WHEN n['ts_Risc2_' + i + '_time'] >= datetime('2022-12-01T00:00:00Z') AND n['ts_Risc2_' + i + '_time'] < datetime('2022-12-02T00:00:00Z') THEN [n['ts_Risc2_' + i + '_time'], n['ts_Risc2_' + i + '_value']]
	 	      ELSE null
	 	    END
	 	  ) AS ts_Risc2_props`,

	//////////
	// #7 ////
	//////////

	// query a node b if it occurs in pattern (a)-[r]->(b)
	// NOTE: time series inside elements are not filetered by the time interval
	`MATCH (a)-[r]->(b)
	     WHERE a.end >= datetime('` + X + `') AND a.start <= datetime('` + Y + `') AND
	 				  r.end >= datetime('` + X + `') AND r.start <= datetime('` + Y + `') AND
	 				  b.end >= datetime('` + X + `') AND b.start <= datetime('` + Y + `')
	  RETURN b`,

	//////////
	// #3 ////
	//////////

	// query a time series property of all nodes (that have this property)
	`
	 MATCH (n)
	 	  WHERE n.end >= datetime('` + X + `') AND n.start <= datetime('` + Y + `')
	 	WITH n, [prop IN keys(n) WHERE prop STARTS WITH 'ts_Risc_'] AS riscProps
	 	   WITH n, size(riscProps) / 2 AS ts_Risc_numbers
	 	WITH n, range(0, ts_Risc_numbers - 1) AS indices
	 RETURN
	 	REDUCE(acc = [], i IN indices |
	 		acc + CASE
	 			WHEN n['ts_Risc_' + i + '_time'] >= datetime('` + X + `') AND n['ts_Risc_' + i + '_time'] < datetime('` + Y + `') THEN [n['ts_Risc_' + i + '_time'],n['ts_Risc_' + i + '_value']]
	 			ELSE null
	 		END
	 	) AS props`,

	//////////
	// #5 ////
	//////////

	// query multiple time series properties of all nodes n
	`MATCH (n)
		WHERE n.end >= datetime('2022-12-01T00:00:00Z') AND n.start <= datetime('2022-12-02T00:00:00Z')
		WITH n,
		  [prop IN keys(n) WHERE prop STARTS WITH 'ts_IP_'] AS ts_IP_props,
		  [prop IN keys(n) WHERE prop STARTS WITH 'ts_Risc_'] AS ts_Risc_props,
		  [prop IN keys(n) WHERE prop STARTS WITH 'ts_Risc1_'] AS ts_Risc1_props,
		  [prop IN keys(n) WHERE prop STARTS WITH 'ts_Risc2_'] AS ts_Risc2_props
		WITH n,
		  size(ts_IP_props) / 2 AS ts_IP_numbers,
		  size(ts_Risc_props) / 2 AS ts_Risc_numbers,
		  size(ts_Risc1_props) / 2 AS ts_Risc1_numbers,
		  size(ts_Risc2_props) / 2 AS ts_Risc2_numbers,
		  ts_IP_props,
		  ts_Risc_props,
		  ts_Risc1_props,
		  ts_Risc2_props
		WITH n,
		  range(0, ts_IP_numbers - 1) AS ts_IP_indices,
		  range(0, ts_Risc_numbers - 1) AS ts_Risc_indices,
		  range(0, ts_Risc1_numbers - 1) AS ts_Risc1_indices,
		  range(0, ts_Risc2_numbers - 1) AS ts_Risc2_indices,
		  ts_IP_props,
		  ts_Risc_props,
		  ts_Risc1_props,
		  ts_Risc2_props
		RETURN
		  REDUCE(acc = [], i IN ts_IP_indices |
		    acc + CASE
		      WHEN n['ts_IP_' + i + '_time'] >= datetime('2022-12-01T00:00:00Z') AND n['ts_IP_' + i + '_time'] < datetime('2022-12-02T00:00:00Z') THEN [n['ts_IP_' + i + '_time'], n['ts_IP_' + i + '_value']]
		      ELSE null
		    END
		  ) AS ts_IP_props,
		  REDUCE(acc = [], i IN ts_Risc_indices |
		    acc + CASE
		      WHEN n['ts_Risc_' + i + '_time'] >= datetime('2022-12-01T00:00:00Z') AND n['ts_Risc_' + i + '_time'] < datetime('2022-12-02T00:00:00Z') THEN [n['ts_Risc_' + i + '_time'], n['ts_Risc_' + i + '_value']]
		      ELSE null
		    END
		  ) AS ts_Risc_props,
		  REDUCE(acc = [], i IN ts_Risc1_indices |
		    acc + CASE
		      WHEN n['ts_Risc1_' + i + '_time'] >= datetime('2022-12-01T00:00:00Z') AND n['ts_Risc1_' + i + '_time'] < datetime('2022-12-02T00:00:00Z') THEN [n['ts_Risc1_' + i + '_time'], n['ts_Risc1_' + i + '_value']]
		      ELSE null
		    END
		  ) AS ts_Risc1_props,
		  REDUCE(acc = [], i IN ts_Risc2_indices |
		    acc + CASE
		      WHEN n['ts_Risc2_' + i + '_time'] >= datetime('2022-12-01T00:00:00Z') AND n['ts_Risc2_' + i + '_time'] < datetime('2022-12-02T00:00:00Z') THEN [n['ts_Risc2_' + i + '_time'], n['ts_Risc2_' + i + '_value']]
		      ELSE null
		    END
		  ) AS ts_Risc2_props`,

	//////////
	// #6 ////
	//////////

	// query a time series property of all nodes if ANY(prop) > 20 (that have this property)
	// returns all, but still not ordered

	// this one is a list of values  [value,value,...]
	// they are ordered by time already because they came from ts_Risc_1_time, ts_Risc_2_time, ...
	` MATCH (n)
	  		WHERE n.end >= datetime('2022-12-01T00:00:00Z') AND n.start <= datetime('2022-12-02T00:00:00Z')
	  			WITH n, [prop IN keys(n) WHERE prop STARTS WITH 'ts_Risc_'] AS riscProps
	  			WITH n, size(riscProps) / 2 AS ts_Risc_numbers
	  			WITH n, range(0, ts_Risc_numbers - 1) AS indices
	  			WITH REDUCE(acc = [], i IN indices |
	  					acc + CASE
	  							WHEN n['ts_Risc_' + i + '_time'] >= datetime('2022-12-01T00:00:00Z') AND
	  								   n['ts_Risc_' + i + '_time'] < datetime('2022-12-02T00:00:00Z') THEN
	  									 n['ts_Risc_' + i + '_value']
	  							ELSE null
	  					END
	  			) AS props
	  			WITH props, [prop IN props WHERE prop > 20] AS filteredProps
	  			WHERE size(filteredProps) > 0
	  	RETURN props`,

	// this one is with timestamps in result list [timestamp,value,timestamp,value,...]
	// they are ordered by time already because the came from ts_Risc_1, ts_Risc_2, ...

	`MATCH (n)
	 WHERE n.end >= datetime('2022-12-01T00:00:00Z') AND n.start <= datetime('2022-12-02T00:00:00Z')
	 	WITH n, [prop IN keys(n) WHERE prop STARTS WITH 'ts_Risc_'] AS riscProps
	 	WITH n, size(riscProps) / 2 AS ts_Risc_numbers
	 	WITH n, range(0, ts_Risc_numbers - 1) AS indices
	 	WITH REDUCE(acc = [], i IN indices |
	 					acc + CASE
	 									WHEN
	 										n['ts_Risc_' + i + '_time'] >= datetime('2022-12-01T00:00:00Z') AND
	 										n['ts_Risc_' + i + '_time'] < datetime('2022-12-02T00:00:00Z')
	 										THEN [n['ts_Risc_' + i + '_time'], n['ts_Risc_' + i + '_value']]
	 									ELSE null
	 					END
	 	) AS time_series
	 	WITH time_series, [i IN range(0, size(time_series) - 1, 2) WHERE time_series[i+1] > 20 | time_series[i]] AS filteredProps
	 	WHERE size(filteredProps) > 0
	 RETURN time_series
	 	`,

	//`MATCH (a)-[r1]->(b)-[r2]->(c)
	//    WHERE a.end >= datetime('` + X + `') AND a.start <= datetime('` + Y + `') AND
	//				  r1.end >= datetime('` + X + `') AND r1.start <= datetime('` + Y + `') AND
	//				  b.end >= datetime('` + X + `') AND b.start <= datetime('` + Y + `') AND
	//					r2.end >= datetime('` + X + `') AND r2.start <= datetime('` + Y + `') AND
	//				  c.end >= datetime('` + X + `') AND c.start <= datetime('` + Y + `')
	// RETURN c`,
}

var ttDBQueries []string = []string{
	"FROM " + X + " TO " + Y + " MATCH (n) WHERE n.nodeid = 0 RETURN n",                                            // 1
	"FROM " + X + " TO " + Y + " MATCH (n) WHERE n.nodeid = 0 RETURN n.ts_Risc",                                    // 2
	"FROM " + X + " TO " + Y + " MATCH (n) WHERE  n.nodeid = 0  RETURN n.ts_IP, n.ts_Risc, n.ts_Risc1, n.ts_Risc2", // 4
	"FROM " + X + " TO " + Y + " MATCH (a)-[r]->(b) RETURN b",                                                      // 7
	"FROM " + X + " TO " + Y + " MATCH (n) RETURN n.ts_Risc",                                                       // 3
	"FROM " + X + " TO " + Y + " MATCH (n) RETURN n.ts_IP, n.ts_Risc, n.ts_Risc1, n.ts_Risc2",                      // 5
	"FROM " + X + " TO " + Y + " MATCH (n) WHERE any(n.ts_Risc) > 20 RETURN n.ts_Risc",                             // 6
}

var ttDBQueriesShallow []string = []string{
	"FROM " + X + " TO " + Y + " SHALLOW MATCH (n) WHERE n.nodeid = 0 RETURN n",                                          // 1
	"FROM " + X + " TO " + Y + " SHALLOW MATCH (n) WHERE n.nodeid = 0 RETURN n.ts_Risc",                                  // 2
	"FROM " + X + " TO " + Y + " SHALLOW MATCH (n) WHERE n.nodeid = 0 RETURN n.ts_IP, n.ts_Risc, n.ts_Risc1, n.ts_Risc2", // 4
	"FROM " + X + " TO " + Y + " SHALLOW MATCH (a)-[r]->(b) RETURN b",                                                    // 7
	"FROM " + X + " TO " + Y + " SHALLOW MATCH (n) RETURN n.ts_Risc",                                                     // 3
	"FROM " + X + " TO " + Y + " SHALLOW MATCH (n) RETURN n.ts_IP, n.ts_Risc, n.ts_Risc1, n.ts_Risc2",                    // 5
	"FROM " + X + " TO " + Y + " SHALLOW MATCH (n) WHERE any(n.ts_Risc) > 20 RETURN n.ts_Risc",                           // 6
}
